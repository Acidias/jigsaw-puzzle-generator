#!/usr/bin/env python3
"""
Siamese Neural Network Training Script
Generated by Jigsaw Puzzle Generator
Model: Test-8
Dataset: Ocean - 2026-02-25 22:56
"""

import os
import json
import time
import pandas as pd
import numpy as np
from PIL import Image

import torch
import torch.nn as nn
import torch.optim as optim
from torch.utils.data import Dataset, DataLoader
import torchvision.transforms as transforms

# ── Configuration ──────────────────────────────────────────────

DATASET_PATH = "./dataset"
INPUT_SIZE = 392
BATCH_SIZE = 32
EPOCHS = 50
LEARNING_RATE = 0.001
EMBEDDING_DIM = 128
DROPOUT = 0.3

if torch.cuda.is_available():
    DEVICE = torch.device("cuda")
elif torch.backends.mps.is_available():
    DEVICE = torch.device("mps")
else:
    DEVICE = torch.device("cpu")
print(f"Using device: {DEVICE}")


# ── Dataset ────────────────────────────────────────────────────

class JigsawPairDataset(Dataset):
    """Loads jigsaw piece pairs from the dataset directory structure."""

    def __init__(self, split_dir, transform=None):
        self.transform = transform
        self.pairs = []

        labels_path = os.path.join(split_dir, "labels.csv")
        if not os.path.exists(labels_path):
            # Scan directories if no labels.csv
            self._scan_directories(split_dir)
        else:
            df = pd.read_csv(labels_path)
            for _, row in df.iterrows():
                left_path = os.path.join(split_dir, row["left_file"])
                right_path = os.path.join(split_dir, row["right_file"])
                label = int(row["label"])
                if os.path.exists(left_path) and os.path.exists(right_path):
                    self.pairs.append((left_path, right_path, label))

    def _scan_directories(self, split_dir):
        for category in os.listdir(split_dir):
            cat_dir = os.path.join(split_dir, category)
            if not os.path.isdir(cat_dir):
                continue
            label = 1 if category == "correct" else 0
            left_files = sorted([
                f for f in os.listdir(cat_dir) if f.endswith("_left.png")
            ])
            for lf in left_files:
                rf = lf.replace("_left.png", "_right.png")
                left_path = os.path.join(cat_dir, lf)
                right_path = os.path.join(cat_dir, rf)
                if os.path.exists(right_path):
                    self.pairs.append((left_path, right_path, label))

    def __len__(self):
        return len(self.pairs)

    def __getitem__(self, idx):
        left_path, right_path, label = self.pairs[idx]
        left_img = Image.open(left_path).convert("RGB")
        right_img = Image.open(right_path).convert("RGB")

        if self.transform:
            left_img = self.transform(left_img)
            right_img = self.transform(right_img)

        return left_img, right_img, torch.tensor(label, dtype=torch.float32)


# ── Model ──────────────────────────────────────────────────────

class SiameseNetwork(nn.Module):
    """Siamese Neural Network with shared-weight CNN backbone."""

    def __init__(self):
        super().__init__()

        # Shared CNN backbone
        layers = []
        in_channels = 3
        # Conv block 1
        layers.append(nn.Conv2d(in_channels, 32, kernel_size=3, padding=1))
        layers.append(nn.BatchNorm2d(32))
        layers.append(nn.ReLU())
        layers.append(nn.MaxPool2d(2))
        in_channels = 32

        # Conv block 2
        layers.append(nn.Conv2d(in_channels, 64, kernel_size=3, padding=1))
        layers.append(nn.BatchNorm2d(64))
        layers.append(nn.ReLU())
        layers.append(nn.MaxPool2d(2))
        in_channels = 64

        # Conv block 3
        layers.append(nn.Conv2d(in_channels, 128, kernel_size=3, padding=1))
        layers.append(nn.BatchNorm2d(128))
        layers.append(nn.ReLU())
        layers.append(nn.MaxPool2d(2))
        in_channels = 128
        layers.append(nn.AdaptiveAvgPool2d((4, 4)))
        self.backbone = nn.Sequential(*layers)

        # Embedding head
        self.embedding = nn.Sequential(
            nn.Flatten(),
            nn.Linear(128 * 4 * 4, EMBEDDING_DIM),
            nn.ReLU(),
            nn.Dropout(DROPOUT),
        )

        # Classification head (outputs raw logits for BCEWithLogitsLoss)
        self.classifier = nn.Sequential(
            nn.Linear(EMBEDDING_DIM, 64),
            nn.ReLU(),
            nn.Dropout(DROPOUT),
            nn.Linear(64, 1),
        )

    def forward_one(self, x):
        """Forward pass through one branch."""
        x = self.backbone(x)
        x = self.embedding(x)
        return x

    def forward(self, left, right):
        """Forward pass through both branches + comparison."""
        emb_left = self.forward_one(left)
        emb_right = self.forward_one(right)
        distance = torch.abs(emb_left - emb_right)
        return self.classifier(distance)


# ── Training ───────────────────────────────────────────────────

def run_train_epoch(model, loader, criterion, optimiser):
    model.train()
    total_loss = 0.0
    correct = 0
    total = 0

    for left, right, labels in loader:
        left, right, labels = left.to(DEVICE), right.to(DEVICE), labels.to(DEVICE)

        optimiser.zero_grad()
        outputs = model(left, right).squeeze()
        loss = criterion(outputs, labels)
        loss.backward()
        optimiser.step()

        total_loss += loss.item() * labels.size(0)
        preds = (outputs > 0.0).float()
        correct += (preds == labels).sum().item()
        total += labels.size(0)

    return total_loss / total, correct / total


def run_validation(model, loader, criterion):
    model.eval()
    total_loss = 0.0
    correct = 0
    total = 0
    all_preds = []
    all_labels = []

    with torch.no_grad():
        for left, right, labels in loader:
            left, right, labels = left.to(DEVICE), right.to(DEVICE), labels.to(DEVICE)

            outputs = model(left, right).squeeze()
            loss = criterion(outputs, labels)

            total_loss += loss.item() * labels.size(0)
            preds = (outputs > 0.0).float()
            correct += (preds == labels).sum().item()
            total += labels.size(0)

            all_preds.extend(preds.cpu().numpy())
            all_labels.extend(labels.cpu().numpy())

    accuracy = correct / total if total > 0 else 0
    avg_loss = total_loss / total if total > 0 else 0

    # Compute precision, recall, F1
    all_preds = np.array(all_preds)
    all_labels = np.array(all_labels)
    tp = ((all_preds == 1) & (all_labels == 1)).sum()
    fp = ((all_preds == 1) & (all_labels == 0)).sum()
    fn = ((all_preds == 0) & (all_labels == 1)).sum()
    precision = tp / (tp + fp) if (tp + fp) > 0 else 0.0
    recall = tp / (tp + fn) if (tp + fn) > 0 else 0.0
    f1 = 2 * precision * recall / (precision + recall) if (precision + recall) > 0 else 0.0

    return avg_loss, accuracy, float(precision), float(recall), float(f1)


def main():
    # Transforms - augmentation for training only
    NORM_MEAN = [0.5, 0.5, 0.5]
    NORM_STD = [0.5, 0.5, 0.5]

    train_transform = transforms.Compose([
        transforms.Resize((INPUT_SIZE, INPUT_SIZE)),
        transforms.ColorJitter(brightness=0.3, contrast=0.3, saturation=0.2),
        transforms.RandomGrayscale(p=0.1),
        transforms.ToTensor(),
        transforms.Normalize(mean=NORM_MEAN, std=NORM_STD),
    ])
    eval_transform = transforms.Compose([
        transforms.Resize((INPUT_SIZE, INPUT_SIZE)),
        transforms.ToTensor(),
        transforms.Normalize(mean=NORM_MEAN, std=NORM_STD),
    ])

    # Load datasets
    train_dataset = JigsawPairDataset(os.path.join(DATASET_PATH, "train"), train_transform)
    valid_dataset = JigsawPairDataset(os.path.join(DATASET_PATH, "valid"), eval_transform)
    test_dataset = JigsawPairDataset(os.path.join(DATASET_PATH, "test"), eval_transform)

    print(f"Train: {len(train_dataset)} pairs")
    print(f"Valid: {len(valid_dataset)} pairs")
    print(f"Test:  {len(test_dataset)} pairs")

    # MPS does not benefit from worker processes (no pin_memory support,
    # and macOS fork overhead outweighs any parallelism gain).
    # CUDA benefits from workers + pinned memory for async transfers.
    use_workers = DEVICE.type == "cuda"
    loader_kwargs = dict(
        num_workers=4 if use_workers else 0,
        pin_memory=use_workers,
        persistent_workers=use_workers,
    )

    train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True, **loader_kwargs)
    valid_loader = DataLoader(valid_dataset, batch_size=BATCH_SIZE, shuffle=False, **loader_kwargs)
    test_loader = DataLoader(test_dataset, batch_size=BATCH_SIZE, shuffle=False, **loader_kwargs)

    # Model
    model = SiameseNetwork().to(DEVICE)
    # Weight positive class to compensate for 1:3 imbalance (25% match, 75% non-match)
    pos_weight = torch.tensor([3.0], device=DEVICE)
    criterion = nn.BCEWithLogitsLoss(pos_weight=pos_weight)
    optimiser = optim.AdamW(model.parameters(), lr=LEARNING_RATE, weight_decay=1e-4)
    scheduler = optim.lr_scheduler.ReduceLROnPlateau(
        optimiser, mode="min", factor=0.5, patience=10
    )

    print(f"\nModel parameters: {sum(p.numel() for p in model.parameters()):,}")
    print(f"Training for {EPOCHS} epochs...\n")

    # Metrics storage
    metrics = {
        "trainLoss": [],
        "validLoss": [],
        "trainAccuracy": [],
        "validAccuracy": [],
    }

    best_valid_loss = float("inf")
    best_epoch = 0
    start_time = time.time()

    for epoch in range(1, EPOCHS + 1):
        train_loss, train_acc = run_train_epoch(model, train_loader, criterion, optimiser)
        valid_loss, valid_acc, _, _, _ = run_validation(model, valid_loader, criterion)

        metrics["trainLoss"].append({"epoch": epoch, "value": round(train_loss, 6)})
        metrics["validLoss"].append({"epoch": epoch, "value": round(valid_loss, 6)})
        metrics["trainAccuracy"].append({"epoch": epoch, "value": round(train_acc, 6)})
        metrics["validAccuracy"].append({"epoch": epoch, "value": round(valid_acc, 6)})

        # Checkpoint best model
        if valid_loss < best_valid_loss:
            best_valid_loss = valid_loss
            best_epoch = epoch
            torch.save(model.state_dict(), "best_model.pth")

        # Step LR scheduler based on validation loss
        old_lr = optimiser.param_groups[0]["lr"]
        scheduler.step(valid_loss)
        new_lr = optimiser.param_groups[0]["lr"]

        print(
            f"Epoch {epoch:3d}/{EPOCHS} | "
            f"Train Loss: {train_loss:.4f} Acc: {train_acc:.4f} | "
            f"Valid Loss: {valid_loss:.4f} Acc: {valid_acc:.4f}"
            + (" *" if epoch == best_epoch else "")
        )
        if new_lr < old_lr:
            print(f"  >> LR reduced: {old_lr:.6f} -> {new_lr:.6f}")

    duration = time.time() - start_time

    # Test with best model
    model.load_state_dict(torch.load("best_model.pth", weights_only=True))
    test_loss, test_acc, test_prec, test_rec, test_f1 = run_validation(model, test_loader, criterion)

    print(f"\n{'='*60}")
    print(f"Training complete in {duration:.1f}s")
    print(f"Best epoch: {best_epoch}")
    print(f"Test Loss: {test_loss:.4f} | Test Acc: {test_acc:.4f}")
    print(f"Precision: {test_prec:.4f} | Recall: {test_rec:.4f} | F1: {test_f1:.4f}")

    # Save metrics
    metrics["testLoss"] = round(test_loss, 6)
    metrics["testAccuracy"] = round(test_acc, 6)
    metrics["testPrecision"] = round(test_prec, 6)
    metrics["testRecall"] = round(test_rec, 6)
    metrics["testF1"] = round(test_f1, 6)
    metrics["trainingDurationSeconds"] = round(duration, 2)
    metrics["bestEpoch"] = best_epoch

    with open("metrics.json", "w") as f:
        json.dump(metrics, f, indent=2)
    print("Saved metrics.json")

    # Export to Core ML (optional - requires coremltools)
    try:
        import coremltools as ct

        model.cpu()
        example_left = torch.randn(1, 3, INPUT_SIZE, INPUT_SIZE)
        example_right = torch.randn(1, 3, INPUT_SIZE, INPUT_SIZE)
        traced = torch.jit.trace(model, (example_left, example_right))

        ml_model = ct.convert(
            traced,
            inputs=[
                ct.TensorType(name="left", shape=(1, 3, INPUT_SIZE, INPUT_SIZE)),
                ct.TensorType(name="right", shape=(1, 3, INPUT_SIZE, INPUT_SIZE)),
            ],
        )
        ml_model.save("model.mlpackage")
        print("Saved model.mlpackage")
    except ImportError:
        print("coremltools not installed - skipping Core ML export")
    except Exception as e:
        print(f"Core ML export failed: {e}")


if __name__ == "__main__":
    main()