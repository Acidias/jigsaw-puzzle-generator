import CryptoKit
import Foundation

/// Generates self-contained PyTorch training scripts for Siamese networks.
/// Stateless enum - all methods are static.
enum TrainingScriptGenerator {

    /// Compute SHA-256 hex hash of a string.
    private static func sha256Hex(_ string: String) -> String {
        let data = Data(string.utf8)
        let digest = SHA256.hash(data: data)
        return digest.map { String(format: "%02x", $0) }.joined()
    }

    /// Generate the full training script as a string.
    @MainActor
    static func generateScript(model: SiameseModel, datasetPath: String = "./dataset") -> String {
        let arch = model.architecture
        return """
        #!/usr/bin/env python3
        \"\"\"
        Siamese Neural Network Training Script
        Generated by Jigsaw Puzzle Generator
        Model: \(model.name)
        Dataset: \(model.sourceDatasetName)
        \"\"\"

        import os
        import json
        import time
        import pandas as pd
        import numpy as np
        from PIL import Image

        import torch
        import torch.nn as nn
        import torch.nn.functional as F
        import torch.optim as optim
        from torch.utils.data import Dataset, DataLoader
        import torchvision.transforms as transforms

        # ── Configuration ──────────────────────────────────────────────

        DATASET_PATH = "\(datasetPath)"
        INPUT_SIZE = \(arch.inputSize)
        BATCH_SIZE = \(arch.batchSize)
        EPOCHS = \(arch.epochs)
        LEARNING_RATE = \(arch.learningRate)
        EMBEDDING_DIM = \(arch.embeddingDimension)
        DROPOUT = \(arch.dropout)

        \(generateDeviceSelectionPython(arch.devicePreference))


        # ── Dataset ────────────────────────────────────────────────────

        class JigsawPairDataset(Dataset):
            \"\"\"Loads jigsaw piece pairs from the dataset directory structure.\"\"\"

            def __init__(self, split_dir, transform=None):
                self.transform = transform
                self.pairs = []
                self.categories = []

                labels_path = os.path.join(split_dir, "labels.csv")
                if not os.path.exists(labels_path):
                    # Scan directories if no labels.csv
                    self._scan_directories(split_dir)
                else:
                    df = pd.read_csv(labels_path)
                    for _, row in df.iterrows():
                        left_path = os.path.join(split_dir, row["left_file"])
                        right_path = os.path.join(split_dir, row["right_file"])
                        label = int(row["label"])
                        category = row["left_file"].split("/")[0]
                        if os.path.exists(left_path) and os.path.exists(right_path):
                            self.pairs.append((left_path, right_path, label))
                            self.categories.append(category)

            def _scan_directories(self, split_dir):
                for category in os.listdir(split_dir):
                    cat_dir = os.path.join(split_dir, category)
                    if not os.path.isdir(cat_dir):
                        continue
                    label = 1 if category == "correct" else 0
                    left_files = sorted([
                        f for f in os.listdir(cat_dir) if f.endswith("_left.png")
                    ])
                    for lf in left_files:
                        rf = lf.replace("_left.png", "_right.png")
                        left_path = os.path.join(cat_dir, lf)
                        right_path = os.path.join(cat_dir, rf)
                        if os.path.exists(right_path):
                            self.pairs.append((left_path, right_path, label))
                            self.categories.append(category)

            def __len__(self):
                return len(self.pairs)

            def __getitem__(self, idx):
                left_path, right_path, label = self.pairs[idx]
                left_img = Image.open(left_path).convert("RGBA")
                right_img = Image.open(right_path).convert("RGBA")

                if self.transform:
                    left_img = self.transform(left_img)
                    right_img = self.transform(right_img)

                return left_img, right_img, torch.tensor(label, dtype=torch.float32)


        # ── Model ──────────────────────────────────────────────────────

        class SiameseNetwork(nn.Module):
            \"\"\"Siamese Neural Network with shared-weight CNN backbone.\"\"\"

            def __init__(self):
                super().__init__()

                # Shared CNN backbone
                layers = []
                in_channels = 4  # RGBA: RGB + alpha (piece silhouette)
        \(generateConvBlocksPython(arch.convBlocks))
                self.backbone = nn.Sequential(*layers)
                self.pool = nn.AdaptiveAvgPool2d((\(SiameseArchitecture.adaptivePoolSize), \(SiameseArchitecture.adaptivePoolSize)))

                # Embedding head
                self.embedding = nn.Sequential(
                    nn.Flatten(),
                    nn.Linear(\(arch.flattenedSize), EMBEDDING_DIM),
                    nn.ReLU(),
                    nn.Dropout(DROPOUT),
                )

        \(generateComparisonPython(arch.comparisonMethod, embeddingDim: arch.embeddingDimension))

            def forward_one(self, x):
                \"\"\"Forward pass through one branch.\"\"\"
                x = self.backbone(x)
                # Pad spatial dims to be divisible by pool output size (MPS compatibility)
                ps = \(SiameseArchitecture.adaptivePoolSize)
                pad_h = (-x.shape[2]) % ps
                pad_w = (-x.shape[3]) % ps
                if pad_h > 0 or pad_w > 0:
                    x = F.pad(x, [0, pad_w, 0, pad_h])
                x = self.pool(x)
                x = self.embedding(x)
                return x

            def forward(self, left, right):
                \"\"\"Forward pass through both branches + comparison.\"\"\"
                emb_left = self.forward_one(left)
                emb_right = self.forward_one(right)
        \(generateForwardComparisonPython(arch.comparisonMethod))


        # ── Training ───────────────────────────────────────────────────

        def run_train_epoch(model, loader, criterion, optimiser):
            model.train()
            total_loss = 0.0
            correct = 0
            total = 0

            for left, right, labels in loader:
                left, right, labels = left.to(DEVICE), right.to(DEVICE), labels.to(DEVICE)

                optimiser.zero_grad()
                outputs = model(left, right).squeeze()
                loss = criterion(outputs, labels)
                loss.backward()
                optimiser.step()

                total_loss += loss.item() * labels.size(0)
                preds = (outputs > 0.0).float()
                correct += (preds == labels).sum().item()
                total += labels.size(0)

            return total_loss / total, correct / total


        def run_validation(model, loader, criterion):
            model.eval()
            total_loss = 0.0
            correct = 0
            total = 0
            all_preds = []
            all_labels = []

            with torch.no_grad():
                for left, right, labels in loader:
                    left, right, labels = left.to(DEVICE), right.to(DEVICE), labels.to(DEVICE)

                    outputs = model(left, right).squeeze()
                    loss = criterion(outputs, labels)

                    total_loss += loss.item() * labels.size(0)
                    preds = (outputs > 0.0).float()
                    correct += (preds == labels).sum().item()
                    total += labels.size(0)

                    all_preds.extend(preds.cpu().numpy())
                    all_labels.extend(labels.cpu().numpy())

            accuracy = correct / total if total > 0 else 0
            avg_loss = total_loss / total if total > 0 else 0

            # Compute precision, recall, F1
            all_preds = np.array(all_preds)
            all_labels = np.array(all_labels)
            tp = ((all_preds == 1) & (all_labels == 1)).sum()
            fp = ((all_preds == 1) & (all_labels == 0)).sum()
            fn = ((all_preds == 0) & (all_labels == 1)).sum()
            precision = tp / (tp + fp) if (tp + fp) > 0 else 0.0
            recall = tp / (tp + fn) if (tp + fn) > 0 else 0.0
            f1 = 2 * precision * recall / (precision + recall) if (precision + recall) > 0 else 0.0

            return avg_loss, accuracy, float(precision), float(recall), float(f1)


        def run_detailed_test(model, dataset, criterion):
            \"\"\"Detailed test with confusion matrix and per-category breakdown.\"\"\"
            model.eval()

            use_workers = DEVICE.type == "cuda"
            loader_kwargs = dict(
                num_workers=4 if use_workers else 0,
                pin_memory=use_workers,
                persistent_workers=use_workers,
            )
            loader = DataLoader(dataset, batch_size=BATCH_SIZE, shuffle=False, **loader_kwargs)

            all_preds = []
            all_labels = []

            with torch.no_grad():
                for left, right, labels in loader:
                    left, right, labels = left.to(DEVICE), right.to(DEVICE), labels.to(DEVICE)
                    outputs = model(left, right).squeeze()
                    preds = (outputs > 0.0).float()
                    all_preds.extend(preds.cpu().numpy())
                    all_labels.extend(labels.cpu().numpy())

            all_preds = np.array(all_preds)
            all_labels = np.array(all_labels)

            # Binary confusion matrix
            tp = int(((all_preds == 1) & (all_labels == 1)).sum())
            fp = int(((all_preds == 1) & (all_labels == 0)).sum())
            fn = int(((all_preds == 0) & (all_labels == 1)).sum())
            tn = int(((all_preds == 0) & (all_labels == 0)).sum())

            confusion_matrix = {
                "truePositives": tp,
                "falsePositives": fp,
                "falseNegatives": fn,
                "trueNegatives": tn,
            }

            # Per-category breakdown (uses dataset.categories which parallels pairs order)
            per_category = {}
            for cat in sorted(set(dataset.categories)):
                mask = np.array([c == cat for c in dataset.categories])
                cat_preds = all_preds[mask]
                total = int(len(cat_preds))
                predicted_match = int((cat_preds == 1).sum())
                per_category[cat] = {
                    "total": total,
                    "predictedMatch": predicted_match,
                    "predictedNonMatch": total - predicted_match,
                }

            return confusion_matrix, per_category


        class RGBAAugment:
            \"\"\"Apply colour augmentations to RGB channels only, preserving alpha.\"\"\"

            def __init__(self, rgb_aug):
                self.rgb_aug = rgb_aug

            def __call__(self, img):
                r, g, b, a = img.split()
                rgb = Image.merge("RGB", (r, g, b))
                rgb = self.rgb_aug(rgb)
                r2, g2, b2 = rgb.split()
                return Image.merge("RGBA", (r2, g2, b2, a))


        def main():
            # Transforms - augmentation for training only (RGBA: 4 channels)
            NORM_MEAN = [0.5, 0.5, 0.5, 0.5]
            NORM_STD = [0.5, 0.5, 0.5, 0.5]

            train_transform = transforms.Compose([
                transforms.Resize((INPUT_SIZE, INPUT_SIZE)),
                RGBAAugment(transforms.Compose([
                    transforms.ColorJitter(brightness=0.3, contrast=0.3, saturation=0.2),
                    transforms.RandomGrayscale(p=0.1),
                ])),
                transforms.ToTensor(),
                transforms.Normalize(mean=NORM_MEAN, std=NORM_STD),
            ])
            eval_transform = transforms.Compose([
                transforms.Resize((INPUT_SIZE, INPUT_SIZE)),
                transforms.ToTensor(),
                transforms.Normalize(mean=NORM_MEAN, std=NORM_STD),
            ])

            # Load datasets
            train_dataset = JigsawPairDataset(os.path.join(DATASET_PATH, "train"), train_transform)
            valid_dataset = JigsawPairDataset(os.path.join(DATASET_PATH, "valid"), eval_transform)
            test_dataset = JigsawPairDataset(os.path.join(DATASET_PATH, "test"), eval_transform)

            print(f"Train: {len(train_dataset)} pairs")
            print(f"Valid: {len(valid_dataset)} pairs")
            print(f"Test:  {len(test_dataset)} pairs")

            # MPS does not benefit from worker processes (no pin_memory support,
            # and macOS fork overhead outweighs any parallelism gain).
            # CUDA benefits from workers + pinned memory for async transfers.
            use_workers = DEVICE.type == "cuda"
            loader_kwargs = dict(
                num_workers=4 if use_workers else 0,
                pin_memory=use_workers,
                persistent_workers=use_workers,
            )

            train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True, **loader_kwargs)
            valid_loader = DataLoader(valid_dataset, batch_size=BATCH_SIZE, shuffle=False, **loader_kwargs)
            test_loader = DataLoader(test_dataset, batch_size=BATCH_SIZE, shuffle=False, **loader_kwargs)

            # Model
            model = SiameseNetwork().to(DEVICE)
            # Weight positive class to compensate for 1:3 imbalance (25% match, 75% non-match)
            pos_weight = torch.tensor([3.0], device=DEVICE)
            criterion = nn.BCEWithLogitsLoss(pos_weight=pos_weight)
            optimiser = optim.AdamW(model.parameters(), lr=LEARNING_RATE, weight_decay=1e-4)
            scheduler = optim.lr_scheduler.ReduceLROnPlateau(
                optimiser, mode="min", factor=0.5, patience=10
            )

            print(f"\\nModel parameters: {sum(p.numel() for p in model.parameters()):,}")
            print(f"Training for {EPOCHS} epochs...\\n")

            # Metrics storage
            metrics = {
                "trainLoss": [],
                "validLoss": [],
                "trainAccuracy": [],
                "validAccuracy": [],
            }

            best_valid_loss = float("inf")
            best_epoch = 0
            start_time = time.time()

            for epoch in range(1, EPOCHS + 1):
                train_loss, train_acc = run_train_epoch(model, train_loader, criterion, optimiser)
                valid_loss, valid_acc, _, _, _ = run_validation(model, valid_loader, criterion)

                metrics["trainLoss"].append({"epoch": epoch, "value": round(train_loss, 6)})
                metrics["validLoss"].append({"epoch": epoch, "value": round(valid_loss, 6)})
                metrics["trainAccuracy"].append({"epoch": epoch, "value": round(train_acc, 6)})
                metrics["validAccuracy"].append({"epoch": epoch, "value": round(valid_acc, 6)})

                # Checkpoint best model
                if valid_loss < best_valid_loss:
                    best_valid_loss = valid_loss
                    best_epoch = epoch
                    torch.save(model.state_dict(), "best_model.pth")

                # Step LR scheduler based on validation loss
                old_lr = optimiser.param_groups[0]["lr"]
                scheduler.step(valid_loss)
                new_lr = optimiser.param_groups[0]["lr"]

                print(
                    f"Epoch {epoch:3d}/{EPOCHS} | "
                    f"Train Loss: {train_loss:.4f} Acc: {train_acc:.4f} | "
                    f"Valid Loss: {valid_loss:.4f} Acc: {valid_acc:.4f}"
                    + (" *" if epoch == best_epoch else "")
                )
                if new_lr < old_lr:
                    print(f"  >> LR reduced: {old_lr:.6f} -> {new_lr:.6f}")

            duration = time.time() - start_time

            # Test with best model
            model.load_state_dict(torch.load("best_model.pth", weights_only=True))
            test_loss, test_acc, test_prec, test_rec, test_f1 = run_validation(model, test_loader, criterion)

            # Detailed test: confusion matrix + per-category breakdown
            confusion_matrix, per_category = run_detailed_test(model, test_dataset, criterion)

            print(f"\\n{'='*60}")
            print(f"Training complete in {duration:.1f}s")
            print(f"Best epoch: {best_epoch}")
            print(f"Test Loss: {test_loss:.4f} | Test Acc: {test_acc:.4f}")
            print(f"Precision: {test_prec:.4f} | Recall: {test_rec:.4f} | F1: {test_f1:.4f}")
            print(f"\\nConfusion Matrix:")
            print(f"  TP: {confusion_matrix['truePositives']}  FP: {confusion_matrix['falsePositives']}")
            print(f"  FN: {confusion_matrix['falseNegatives']}  TN: {confusion_matrix['trueNegatives']}")
            print(f"\\nPer-category results:")
            for cat, res in per_category.items():
                print(f"  {cat}: {res['predictedMatch']}/{res['total']} predicted match")

            # Save metrics
            metrics["testLoss"] = round(test_loss, 6)
            metrics["testAccuracy"] = round(test_acc, 6)
            metrics["testPrecision"] = round(test_prec, 6)
            metrics["testRecall"] = round(test_rec, 6)
            metrics["testF1"] = round(test_f1, 6)
            metrics["trainingDurationSeconds"] = round(duration, 2)
            metrics["bestEpoch"] = best_epoch
            metrics["confusionMatrix"] = confusion_matrix
            metrics["perCategoryResults"] = per_category

            with open("metrics.json", "w") as f:
                json.dump(metrics, f, indent=2)
            print("Saved metrics.json")

            # Export to Core ML (optional - requires coremltools)
            try:
                import coremltools as ct

                model.cpu()
                example_left = torch.randn(1, 4, INPUT_SIZE, INPUT_SIZE)
                example_right = torch.randn(1, 4, INPUT_SIZE, INPUT_SIZE)
                traced = torch.jit.trace(model, (example_left, example_right))

                ml_model = ct.convert(
                    traced,
                    inputs=[
                        ct.TensorType(name="left", shape=(1, 4, INPUT_SIZE, INPUT_SIZE)),
                        ct.TensorType(name="right", shape=(1, 4, INPUT_SIZE, INPUT_SIZE)),
                    ],
                )
                ml_model.save("model.mlpackage")
                print("Saved model.mlpackage")
            except ImportError:
                print("coremltools not installed - skipping Core ML export")
            except Exception as e:
                print(f"Core ML export failed: {e}")


        if __name__ == "__main__":
            main()
        """
    }

    /// Export a complete training package (script + requirements + optionally the dataset).
    /// Returns the SHA-256 hex hash of the generated training script.
    @discardableResult
    @MainActor
    static func exportTrainingPackage(
        model: SiameseModel,
        dataset: PuzzleDataset,
        to destination: URL,
        includeDataset: Bool = true
    ) throws -> String {
        let fm = FileManager.default
        try fm.createDirectory(at: destination, withIntermediateDirectories: true)

        // Write train.py
        let datasetRelPath = includeDataset ? "./dataset" : "<path-to-dataset>"
        let script = generateScript(model: model, datasetPath: datasetRelPath)
        let scriptURL = destination.appendingPathComponent("train.py")
        try script.write(to: scriptURL, atomically: true, encoding: .utf8)

        // Write requirements.txt
        let requirements = """
        torch>=2.0
        torchvision>=0.15
        Pillow>=9.0
        pandas>=1.5
        numpy>=1.24
        coremltools>=7.0
        scikit-learn>=1.2
        """
        let reqURL = destination.appendingPathComponent("requirements.txt")
        try requirements.write(to: reqURL, atomically: true, encoding: .utf8)

        // Optionally copy dataset
        if includeDataset {
            let datasetDest = destination.appendingPathComponent("dataset")
            try DatasetStore.exportDataset(dataset, to: datasetDest)
        }

        return sha256Hex(script)
    }

    /// Write just train.py + requirements.txt to a directory (for TrainingRunner).
    /// The script points directly at the given dataset path - no dataset copying.
    /// Returns the SHA-256 hex hash of the generated training script.
    @discardableResult
    @MainActor
    static func writeTrainingFiles(model: SiameseModel, datasetPath: String, to directory: URL) throws -> String {
        let fm = FileManager.default
        try fm.createDirectory(at: directory, withIntermediateDirectories: true)

        let script = generateScript(model: model, datasetPath: datasetPath)
        let scriptURL = directory.appendingPathComponent("train.py")
        try script.write(to: scriptURL, atomically: true, encoding: .utf8)

        let requirements = """
        torch>=2.0
        torchvision>=0.15
        Pillow>=9.0
        pandas>=1.5
        numpy>=1.24
        coremltools>=7.0
        scikit-learn>=1.2
        """
        let reqURL = directory.appendingPathComponent("requirements.txt")
        try requirements.write(to: reqURL, atomically: true, encoding: .utf8)

        return sha256Hex(script)
    }

    // MARK: - Python Code Generation Helpers

    private static func generateConvBlocksPython(_ blocks: [ConvBlock]) -> String {
        var lines: [String] = []
        for (i, block) in blocks.enumerated() {
            let pad = block.kernelSize / 2
            lines.append("        # Conv block \(i + 1)")
            lines.append("        layers.append(nn.Conv2d(in_channels, \(block.filters), kernel_size=\(block.kernelSize), padding=\(pad)))")
            if block.useBatchNorm {
                lines.append("        layers.append(nn.BatchNorm2d(\(block.filters)))")
            }
            lines.append("        layers.append(nn.ReLU())")
            if block.useMaxPool {
                lines.append("        layers.append(nn.MaxPool2d(2))")
            }
            lines.append("        in_channels = \(block.filters)")
            if i < blocks.count - 1 {
                lines.append("")
            }
        }
        return lines.joined(separator: "\n")
    }

    private static func generateComparisonPython(_ method: ComparisonMethod, embeddingDim: Int) -> String {
        switch method {
        case .l1Distance, .l2Distance:
            return """
                    # Classification head (outputs raw logits for BCEWithLogitsLoss)
                    self.classifier = nn.Sequential(
                        nn.Linear(EMBEDDING_DIM, 64),
                        nn.ReLU(),
                        nn.Dropout(DROPOUT),
                        nn.Linear(64, 1),
                    )
            """
        case .concatenation:
            return """
                    # Classification head (outputs raw logits for BCEWithLogitsLoss)
                    self.classifier = nn.Sequential(
                        nn.Linear(EMBEDDING_DIM * 2, 128),
                        nn.ReLU(),
                        nn.Dropout(DROPOUT),
                        nn.Linear(128, 64),
                        nn.ReLU(),
                        nn.Linear(64, 1),
                    )
            """
        }
    }

    private static func generateDeviceSelectionPython(_ preference: DevicePreference) -> String {
        switch preference {
        case .auto:
            return """
            if torch.cuda.is_available():
                DEVICE = torch.device("cuda")
            elif torch.backends.mps.is_available():
                DEVICE = torch.device("mps")
            else:
                DEVICE = torch.device("cpu")
            print(f"Using device: {DEVICE}")
            """
        case .mps:
            return """
            if torch.backends.mps.is_available():
                DEVICE = torch.device("mps")
            else:
                print("Warning: MPS not available, falling back to CPU")
                DEVICE = torch.device("cpu")
            print(f"Using device: {DEVICE}")
            """
        case .cuda:
            return """
            if torch.cuda.is_available():
                DEVICE = torch.device("cuda")
            else:
                print("Warning: CUDA not available, falling back to CPU")
                DEVICE = torch.device("cpu")
            print(f"Using device: {DEVICE}")
            """
        case .cpu:
            return """
            DEVICE = torch.device("cpu")
            print(f"Using device: {DEVICE}")
            """
        }
    }

    private static func generateForwardComparisonPython(_ method: ComparisonMethod) -> String {
        switch method {
        case .l1Distance:
            return """
                    distance = torch.abs(emb_left - emb_right)
                    return self.classifier(distance)
            """
        case .l2Distance:
            return """
                    distance = (emb_left - emb_right).pow(2)
                    return self.classifier(distance)
            """
        case .concatenation:
            return """
                    combined = torch.cat([emb_left, emb_right], dim=1)
                    return self.classifier(combined)
            """
        }
    }
}
